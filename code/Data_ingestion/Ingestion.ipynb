{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data ingestion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv file to parquet file conversion.\n",
    "<br>\n",
    "datetime conversion from unix to general date_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"d:/NILM/Data_files/CSV/\"\n",
    "path_parquet = \"D:/NILM/Data_files/Parquet/Complete_data/\"\n",
    "\n",
    "lst = [ 'mains1', 'mains2', 'fridge', 'ac1', 'ac2', 'washing_machine', 'laptop', 'iron','kitchen','tv','water_filter']\n",
    "columns = ['timestamp','active', 'reactive', 'aparent', 'frequency', 'voltage', 'PF', 'current']\n",
    "for i in range(1,12):\n",
    "    if i<3:\n",
    "        # main file showed error regarding datatypes\n",
    "        pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "        df = pd.read_csv(f\"{path}{i}.csv\", dtype={\"W\": float, \"VAR\": float, \"VA\": float, \"f\": float, \"VLN\": float, \"PF\": float, \"A\": float,\"timestamp\":int}, na_values='\\\\N')\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{path}{i}.csv\")\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df.columns = columns\n",
    "    df.to_parquet(f\"{path_parquet}{lst[(i-1)]}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting and ending of each datafile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mains1 start: 2013-05-24 00:00:00\n",
      "mains1 end: 2013-08-05 15:33:16\n",
      "mains2 start: 2013-05-24 00:00:00\n",
      "mains2 end: 2013-08-05 15:33:16\n",
      "fridge start: 2013-06-07 00:00:00\n",
      "fridge end: 2013-08-05 16:32:04\n",
      "ac1 start: 2013-06-07 15:04:51\n",
      "ac1 end: 2013-09-18 03:10:55\n",
      "ac2 start: 2013-06-07 15:05:18\n",
      "ac2 end: 2013-09-13 13:10:44\n",
      "washing_machine start: 2013-06-10 01:32:00\n",
      "washing_machine end: 2013-08-04 06:59:59\n",
      "laptop start: 2013-06-07 01:04:41\n",
      "laptop end: 2013-08-05 16:32:02\n",
      "iron start: 2013-06-07 09:37:46\n",
      "iron end: 2013-08-04 06:54:41\n",
      "kitchen start: 2013-06-24 04:36:08\n",
      "kitchen end: 2013-08-04 09:22:09\n",
      "tv start: 2013-06-12 06:26:28\n",
      "tv end: 2013-08-05 13:39:15\n",
      "water_filter start: 2013-07-12 09:38:11\n",
      "water_filter end: 2013-08-05 16:32:03\n"
     ]
    }
   ],
   "source": [
    "path_parquet = \"D:/NILM/Data_files/Parquet/Complete_data/\"\n",
    "lst = [ 'mains1', 'mains2', 'fridge', 'ac1', 'ac2', 'washing_machine', 'laptop', 'iron','kitchen','tv','water_filter']\n",
    "\n",
    "for i in range(len(lst)):\n",
    "    df = pd.read_parquet(f\"{path_parquet}/{lst[i]}.parquet\")\n",
    "    # print(lst[i],\":\",len(df))\n",
    "    df.set_index(['timestamp'],drop=True, inplace=True)\n",
    "    print(lst[i],\"start:\",df.first_valid_index())\n",
    "    print(lst[i],\"end:\",df.last_valid_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = '2013-06-12 00:00:00'\n",
    "end_datetime = '2013-06-21 00:00:00'\n",
    "path = \"d:/NILM/Data_files/Parquet/Appliances12_06-21_06/\"\n",
    "\n",
    "for i in range(len(lst)):\n",
    "    df = pd.read_parquet(f\"{path_parquet}/{lst[i]}.parquet\")\n",
    "    # df.set_index(['timestamp'],drop=True, inplace=True)\n",
    "    df.set_index(['timestamp'],drop=True, inplace=True)\n",
    "    df_to_parquet = (df[(df.index >= start_datetime) & (df.index <= end_datetime)])\n",
    "    df_to_parquet.reset_index(inplace=True)\n",
    "    df_to_parquet.to_parquet(f\"{path}{lst[i]}.parquet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
